{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      288,      3717,         0,         0,         0,         0,\n",
       "               0,         0,     65536,         0,         0,   4456448,\n",
       "       503318272,        10,         1,  33554433,       256,       768,\n",
       "               0,         0, 117441024,  19464192,         0,         0,\n",
       "               0,         0,      9728,  84541440,  33554432,         0,\n",
       "          655616,       256,         9,         0,         0,     65536,\n",
       "           22528,         0,         0,         0,         0,        21,\n",
       "           65536,         0,         0,         0,  50331649,     65537,\n",
       "          131072,  67108864,      1280,       541,         0,         0,\n",
       "               0, 805306368,    786432,       768,         0,         0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import feature\n",
    "from scipy import spatial\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "from time import time\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance \n",
    "# Ho 10 personaggi famosi, ognuno con un diverso numero di immagini, per un totale di 2174 immagini.\n",
    "# Lo scopo è: data un'immagine, classificare le 10 immagini più simili alla precedente, in ordine\n",
    "# di similarità.\n",
    "# Importo il file con le LBP features, tenendo conto che i primi due valori sono int32 ed indicano\n",
    "# rispettivamente il numero di facce presenti nella cartella e le LBP features per ogni faccia.\n",
    "arr = np.fromfile(\"./thumbnails_features_deduped_sample/bill gates/feature.bin\", dtype = np.int32)\n",
    "arr[0:60]\n",
    "# Nel caso di Bill Gates, sono presenti 288 immagini, ognuna con 3717 features LBP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1070496"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3717*288\n",
    "# Dunque, in teoria dovrebbero esserci 1070496 elementi (3717 features * 288 facce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267626"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr)\n",
    "# Tuttavia ce ne sono solo 267626 (circa 260mila anzichè un milione). Questo perchè solo i primi due numeri\n",
    "# sono int32, mentre gli altri no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1070504"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.fromfile(\"./thumbnails_features_deduped_sample/bill gates/feature.bin\", dtype = np.int8)\n",
    "len(arr)\n",
    "# Se codifico il file binario in 8 bit anzichè 32 bit noto che ora le dimensioni tornano.\n",
    "# Devo però rimuovere i primi elementi perchè corrispondono ai due interi relativi appunto\n",
    "# al numero di facce e al numero di features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1070496"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = arr[8:]\n",
    "len(arr)\n",
    "# Ora il numero di elementi è esatto e corrisponde solo ed esclusivamente alle features per faccia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    base_path = './thumbnails_features_deduped_sample/'\n",
    "\n",
    "    labels = []\n",
    "    features = []\n",
    "    final_features = []\n",
    "    dimensions = 0\n",
    "\n",
    "    for di,d in enumerate(sorted(os.listdir(base_path))):\n",
    "        features = []\n",
    "        print(d)\n",
    "        # Salvo il numero di facce e il numero di features per faccia nella variabile dim\n",
    "        dim = np.fromfile(base_path+d+'/feature.bin', dtype=np.int32)[0:2] \n",
    "        # Salvo tutte le features (un personaggio alla volta) nella variabile feats\n",
    "        feats = np.fromfile(base_path+d+'/feature.bin', dtype=np.int8)[8:]\n",
    "        # Ora con un ciclo, salvo in cur_features le features dell'immagine corrente\n",
    "        \n",
    "        for i in np.arange(0,dim[0]*dim[1], step = dim[1]):\n",
    "            \n",
    "            cur_features = feats[i:i+dim[1]]\n",
    "            features = np.append(features,[cur_features])\n",
    "        \n",
    "            # Quindi poi aggiungo le features e la label di quell'immagine\n",
    "        \n",
    "        labels = np.append(labels,np.full(dim[0],d))\n",
    "        features = features.reshape(dim[0],dim[1])\n",
    "        \n",
    "        final_features = np.append(final_features,features)\n",
    "        dimensions = dimensions+dim[0]\n",
    "        final_features = np.reshape(final_features,(dimensions,dim[1]))\n",
    "        print([features.shape,final_features.shape])\n",
    "        \n",
    "\n",
    "    # Separazione training / test set\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(final_features, labels, test_size=0.5, shuffle=True, random_state=1)\n",
    "    # X: features, y: labels\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaron carter\n",
      "[(48, 3717), (48, 3717)]\n",
      "adam brody\n",
      "[(83, 3717), (131, 3717)]\n",
      "adrien brody\n",
      "[(76, 3717), (207, 3717)]\n",
      "aishwarya rai\n",
      "[(781, 3717), (988, 3717)]\n",
      "al gore\n",
      "[(175, 3717), (1163, 3717)]\n",
      "bill gates\n",
      "[(288, 3717), (1451, 3717)]\n",
      "liv tyler\n",
      "[(393, 3717), (1844, 3717)]\n",
      "martina hingis\n",
      "[(51, 3717), (1895, 3717)]\n",
      "michelle obama\n",
      "[(123, 3717), (2018, 3717)]\n",
      "steve jobs\n",
      "[(156, 3717), (2174, 3717)]\n"
     ]
    }
   ],
   "source": [
    "# Provo ad eseguirlo\n",
    "prova = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lo scopo però è quello\n",
    "# LBP features normalizzate nello spazio L2\n",
    "norm_0 = dati[0]/np.linalg.norm(dati[0]) \n",
    "norm_1 = dati[500]/np.linalg.norm(dati[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calcolo la distanza euclidea dei due vettori \n",
    "dist = np.linalg.norm(norm_0-norm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5152775427197981"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converto la distanza in similarità tra 0 e 1 (0 molto diversi, 1 uguali)\n",
    "1/(1+dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addestramento completato in 808.323s\n",
      "Migliore combinazione di parametri:\n",
      " C: 1\n",
      " gamma: 1\n"
     ]
    }
   ],
   "source": [
    "# DA QUI IN POI FACCIO ALTRE ROBE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parametri da provare in cross validation\n",
    "param_grid = {'C': [1, 2, 3, 4, 5, 10, 20, 50, 100, 500],\n",
    "          'gamma': [1, 5, 10, 50, 100, 500, 600, 700, 800, 900, 1000], }\n",
    "\n",
    "# Inizializzazione Support Vector Machine\n",
    "clf = GridSearchCV(SVC(kernel='poly', class_weight='balanced'), param_grid, cv=2, n_jobs=-1)\n",
    "\n",
    "# Addestramento\n",
    "t2 = time()\n",
    "clf = clf.fit(prova[0], prova[2])\n",
    "print(\"Addestramento completato in %0.3fs\" % (time() - t2))\n",
    "\n",
    "# Risultato della cross validation\n",
    "print(\"Migliore combinazione di parametri:\")\n",
    "print(\" C: \"+str(clf.best_estimator_.C))\n",
    "print(\" gamma: \"+str(clf.best_estimator_.gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report di classificazione:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  aaron carter       0.94      0.68      0.79        22\n",
      "    adam brody       0.95      0.49      0.65        43\n",
      "  adrien brody       1.00      0.76      0.86        37\n",
      " aishwarya rai       0.89      0.94      0.92       400\n",
      "       al gore       0.87      0.85      0.86        88\n",
      "    bill gates       0.77      0.99      0.86       142\n",
      "     liv tyler       0.82      0.89      0.85       190\n",
      "martina hingis       0.78      0.30      0.44        23\n",
      "michelle obama       1.00      0.64      0.78        76\n",
      "    steve jobs       0.84      0.80      0.82        66\n",
      "\n",
      "     micro avg       0.86      0.86      0.86      1087\n",
      "     macro avg       0.89      0.74      0.78      1087\n",
      "  weighted avg       0.87      0.86      0.85      1087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = clf.predict(prova[1])\n",
    "\n",
    "# Report di classificazione\n",
    "print(\"Report di classificazione:\")\n",
    "print(classification_report(prova[3], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice di confusione:\n",
      "[[ 15   0   0   3   0   0   3   0   0   1]\n",
      " [  0  21   0   6   2   5   5   1   0   3]\n",
      " [  0   0  28   0   2   5   2   0   0   0]\n",
      " [  0   0   0 378   1   7  13   0   0   1]\n",
      " [  0   0   0   3  75   5   5   0   0   0]\n",
      " [  0   0   0   0   0 140   0   0   0   2]\n",
      " [  1   0   0  12   0   6 169   1   0   1]\n",
      " [  0   0   0   9   1   2   3   7   0   1]\n",
      " [  0   1   0  12   2   6   5   0  49   1]\n",
      " [  0   0   0   2   3   7   1   0   0  53]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Matrice di confusione:\")\n",
    "cm = confusion_matrix(prova[3], y_pred)\n",
    "print(cm)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'accuracy ottenuta è pari a 86.0165593376265 %\n"
     ]
    }
   ],
   "source": [
    "# Calcolo accuracy partendo dalla matrice di confusione.\n",
    "# Questa volta non è più una matrice 2x2, ma 10x10, essendo 10 le labels.\n",
    "correct=0\n",
    "for i in range(0,10):\n",
    "    correct= correct+cm[i,i]\n",
    "#correct\n",
    "total = 1087\n",
    "\n",
    "accuracy = correct/total\n",
    "print(\"L'accuracy ottenuta è pari a \" + str(accuracy*100) + \" %\") \n",
    "\n",
    "# Accuracy ottenuta: 86%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
